### Implement a neural network(1 hidden-layer) using python numpy
#### Mnist dataset is used for trainning
The following activation functions can be used:

* softplus: h(a) = log(1+e<sup>a</sup>)
* tanh: h(a) = (e<sup>a</sup> - e<sup>-a</sup>)  /  (e<sup>a</sup> + e<sup>-a</sup>)
*  cosine: h(a) = cos(a)

Output layer computes class probabilities using Softmax function
